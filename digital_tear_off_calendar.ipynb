{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8813d59",
   "metadata": {},
   "source": [
    "# Digital Tear-off Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff962484",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T10:36:34.273854Z",
     "start_time": "2022-10-26T10:36:33.520567Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pytz\n",
    "import geocoder\n",
    "from datetime import datetime\n",
    "from timezonefinder import TimezoneFinder\n",
    "\n",
    "from meteostat import Point, Daily, Stations  # https://meteostat.net/en/blog/obtain-weather-data-any-location-python\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import random\n",
    "import replicate\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8da29e66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T10:36:34.416994Z",
     "start_time": "2022-10-26T10:36:34.275729Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get location.\n",
    "g = geocoder.ip('me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79e4335f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T10:36:34.935361Z",
     "start_time": "2022-10-26T10:36:34.424140Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get date.\n",
    "obj = TimezoneFinder()\n",
    "tz_string = obj.timezone_at(lng=g.lng, lat=g.lat)\n",
    "tz = pytz.timezone(tz_string)\n",
    "local_now = datetime.now(tz)\n",
    "local_date = datetime(local_now.year, local_now.month, local_now.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38b7aca1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T10:36:34.968403Z",
     "start_time": "2022-10-26T10:36:34.937118Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the weather status. (ideally has sunny/rainy/cloudy/etc.. now mainly has temperatures)\n",
    "location = Point(g.lat, g.lng)\n",
    "data = Daily(location, local_date, local_date)\n",
    "data = data.fetch()\n",
    "avg_temp = data.tavg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e40137c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T10:36:34.973751Z",
     "start_time": "2022-10-26T10:36:34.969603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get famous events and famous people's birthdays for the current day from Wikipedia.\n",
    "def scrape_daily_wiki_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    headlines = soup('span', {'class' : 'mw-headline'})\n",
    "    data = {}\n",
    "    for headline in headlines:\n",
    "        if headline.text == \"References\":\n",
    "            return data\n",
    "        if headline.text in [\"Events\", \"Births\", \"Deaths\", \"Holidays and observances\"]:\n",
    "            key = headline.text\n",
    "            data[key] = []\n",
    "        links = headline.find_next('ul').find_all('li')\n",
    "        links = [link.text for link in links]\n",
    "        data[key].extend(links)\n",
    "\n",
    "def get_daily_wiki_url(date):\n",
    "    month_string = date.strftime(\"%B\")\n",
    "    day_string = date.strftime(\"%d\")\n",
    "    wikipedia_url = f\"https://en.wikipedia.org/wiki/{month_string}_{day_string}\"\n",
    "    return wikipedia_url\n",
    "\n",
    "def get_daily_wiki_info(date):\n",
    "    url = get_daily_wiki_url(date)\n",
    "    info = scrape_daily_wiki_url(url)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a78640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T10:36:34.979297Z",
     "start_time": "2022-10-26T10:36:34.975348Z"
    }
   },
   "outputs": [],
   "source": [
    "# Grab headlines of the current day from BBC.\n",
    "def scrape_bbc_headlines():\n",
    "    url='https://www.bbc.com/news'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    headlines = soup.find('body').find_all('h3')\n",
    "    headlines = [x.text.strip() for x in headlines]\n",
    "    return headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45770baf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T10:36:34.983413Z",
     "start_time": "2022-10-26T10:36:34.980634Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an image from prompt.\n",
    "def create_image_from_query(prompt):\n",
    "    model = replicate.models.get(\"stability-ai/stable-diffusion\")\n",
    "    prompt += \" elegant, render, octane, detailed, award winning photography, masterpiece -ar 2:3 -beta -upbeta\"  # Make prompt pretty.\n",
    "    image_url = model.predict(prompt=prompt)[0]\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52b48fa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T10:36:34.988197Z",
     "start_time": "2022-10-26T10:36:34.984552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a daily image based on historic facts from wikipedia.\n",
    "def create_daily_image_wiki():\n",
    "    day_info = get_daily_wiki_info(local_date)\n",
    "    random_fact_type = random.choice(list(day_info.keys()))\n",
    "    random_fact = random.choice(day_info[random_fact_type])\n",
    "    image = create_image_from_query(random_fact)\n",
    "    date_string = f\"{local_date.strftime('%d')} {local_date.strftime('%B')}\"\n",
    "    print(f\"Generated an image of a {random_fact_type} fact for {date_string}.\\n\\n[{random_fact_type} fact]\\n{random_fact}\")\n",
    "    display(image)\n",
    "    return image, random_fact_type, random_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94abef3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T10:36:34.992602Z",
     "start_time": "2022-10-26T10:36:34.989576Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Create a daily image based on historic events from wikipedia.\n",
    "# def create_daily_image_wiki():\n",
    "#     day_info = get_daily_wiki_info(local_date)\n",
    "#     event = random.choice(day_info[\"Events\"])\n",
    "#     image = create_image_from_query(event)\n",
    "#     date_string = f\"{local_date.strftime('%d')} {local_date.strftime('%B')}\"\n",
    "#     print(f\"Generated an image of an Events fact for {date_string}.\\n\\n[Event]\\n{event}\")\n",
    "#     display(image)\n",
    "#     return image, event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0f123cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T10:36:34.998238Z",
     "start_time": "2022-10-26T10:36:34.995461Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_daily_image_bbc():\n",
    "    headlines = scrape_bbc_headlines()\n",
    "    random_headline = random.choice(headlines)\n",
    "    image = create_image_from_query(random_headline)\n",
    "    date_string = f\"{local_date.strftime('%d')} {local_date.strftime('%B')}\"\n",
    "    print(f\"Generated an image for today {date_string} using the following BBC headline:\\n\\n{random_headline}.\")\n",
    "    display(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d5c84e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T10:36:36.260279Z",
     "start_time": "2022-10-26T10:36:34.999891Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ReplicateError",
     "evalue": "You have reached the free time limit.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReplicateError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m image, random_fact_type, random_fact \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_daily_image_wiki\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-------------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m image \u001b[38;5;241m=\u001b[39m create_daily_image_bbc()\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mcreate_daily_image_wiki\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m random_fact_type \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlist\u001b[39m(day_info\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m      5\u001b[0m random_fact \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(day_info[random_fact_type])\n\u001b[0;32m----> 6\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_image_from_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_fact\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m date_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_date\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_date\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated an image of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom_fact_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fact for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom_fact_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fact]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mrandom_fact\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mcreate_image_from_query\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m replicate\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstability-ai/stable-diffusion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m elegant, render, octane, detailed, award winning photography, masterpiece -ar 2:3 -beta -upbeta\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Make prompt pretty.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m image_url \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(image_url)\n\u001b[1;32m      7\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(BytesIO(response\u001b[38;5;241m.\u001b[39mcontent))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/replicate/model.py:20\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReplicateException(\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo versions found for model \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musername, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m latest_version \u001b[38;5;241m=\u001b[39m versions[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlatest_version\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/replicate/version.py:18\u001b[0m, in \u001b[0;36mVersion.predict\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Any, Iterator[Any]]:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# TODO: support args\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Return an iterator of the output\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# FIXME: might just be a list, not an iterator. I wonder if we should differentiate?\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transformed_schema()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/replicate/prediction.py:69\u001b[0m, in \u001b[0;36mPredictionCollection.create\u001b[0;34m(self, version, input, webhook_completed)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m webhook_completed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     body[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwebhook_completed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m webhook_completed\n\u001b[0;32m---> 69\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v1/predictions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m obj \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     75\u001b[0m obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m version\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/replicate/client.py:53\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, method, path, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 53\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ReplicateError(resp\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetail\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (JSONDecodeError, \u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mReplicateError\u001b[0m: You have reached the free time limit."
     ]
    }
   ],
   "source": [
    "image, random_fact_type, random_fact = create_daily_image_wiki()\n",
    "print(\"-------------------------------------------------------------\")\n",
    "image = create_daily_image_bbc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
